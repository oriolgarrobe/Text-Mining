{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/oriolgarrobe/text-mining/blob/master/TM_L5_Erik.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aivf77XYY2BG"
   },
   "source": [
    "# L5: Information extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlgkDEq5Y2BH"
   },
   "source": [
    "Information extraction (IE) is the task of identifying named entities and semantic relations between these entities in text data. In this lab we will focus on two sub-tasks in IE, **named entity recognition** (identifying mentions of entities) and **entity linking** (matching these mentions to entities in a knowledge base)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVhYvcV6Y2BI"
   },
   "source": [
    "We start by loading spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZnGyKP2SY2BI"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7swfKHOY2BK"
   },
   "source": [
    "The data that we will be using has been tokenized following the conventions of the [Penn Treebank](ftp://ftp.cis.upenn.edu/pub/treebank/public_html/tokenization.html), and we need to prevent spaCy from using its own tokenizer on top of this. We therefore override spaCy&rsquo;s tokenizer with one that simply splits on space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2HNqqvMvY2BK"
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "\n",
    "class WhitespaceTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, text):\n",
    "        return Doc(self.vocab, words=text.split(' '))\n",
    "\n",
    "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InD-PsdTY2BK"
   },
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gDK2eXIY2BK"
   },
   "source": [
    "The main data set for this lab is a collection of news wire articles in which mentions of named entities have been annotated with page names from the [English Wikipedia](https://en.wikipedia.org/wiki/). The next code cell loads the training and the development parts of the data into Pandas data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HNgyo31yY2BK"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ner-train.tsv.bz2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2abfad51bc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner-train.tsv.bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_NONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bz2.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0mbz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"t\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bz2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, buffering, compresslevel)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closefp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ner-train.tsv.bz2'"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with bz2.open('ner-train.tsv.bz2', 'rt') as source:\n",
    "    df_train = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)\n",
    "\n",
    "with bz2.open('ner-dev.tsv.bz2', 'rt') as source:\n",
    "    df_dev = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b402LMK0Y2BL"
   },
   "source": [
    "Each row in these two data frames corresponds to one mention of a named entity and has five columns:\n",
    "\n",
    "1. a unique identifier for the sentence containing the entity mention\n",
    "2. the pre-tokenized sentence, with tokens separated by spaces\n",
    "3. the start position of the token span containing the entity mention\n",
    "4. the end position of the token span (exclusive, as in Python list indexing)\n",
    "5. the entity label; either a Wikipedia page name or the generic label `--NME--`\n",
    "\n",
    "The following cell prints the first five samples from the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "GNE1AsTzY2BL",
    "outputId": "bc1839d4-918b-4891-9c15-7c5a579aa797"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nenUt5ByY2BP"
   },
   "source": [
    "In this sample, we see that the first sentence is annotated with three entity mentions:\n",
    "\n",
    "* the span 0–1 &lsquo;EU&rsquo; is annotated as a mention but only labelled with the generic `--NME--`\n",
    "* the span 2–3 &lsquo;German&rsquo; is annotated with the page [Germany](http://en.wikipedia.org/wiki/Germany)\n",
    "* the span 6–7 &lsquo;British&rsquo; is annotated with the page [United_Kingdom](http://en.wikipedia.org/wiki/United_Kingdom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqCU2SzDY2BP"
   },
   "source": [
    "## Problem 1: Evaluation measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPdH114kY2BP"
   },
   "source": [
    "To warm up, we ask you to write code to print the three measures that you will be using for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN5iWcGsY2BQ"
   },
   "outputs": [],
   "source": [
    "def evaluation_report(gold, pred):\n",
    "    \"\"\"Print precision, recall, and F1 score.\n",
    "    \n",
    "    Args:\n",
    "        gold: The set with the gold-standard values.\n",
    "        pred: The set with the predicted values.\n",
    "    \n",
    "    Returns:\n",
    "        Nothing, but prints the precision, recall, and F1 values computed\n",
    "        based on the specified sets.\n",
    "    \"\"\"\n",
    "    # TODO: Replace the next line with your own code\n",
    "    \n",
    "    tp = gold.intersection(pred) # true positives\n",
    "    \n",
    "    precision = len(tp)/len(pred)\n",
    "    \n",
    "    recall = len(tp)/len(gold)\n",
    "    \n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    print(f'Precision: {round(precision*100)}%\\n')\n",
    "    print(f'Recall: {round(recall*100)}%\\n')\n",
    "    print(f'F1-score: {round(f1*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buKrek_iY2BQ"
   },
   "source": [
    "To test your code, you can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQIJ77WHY2BQ",
    "outputId": "18090f76-b513-49af-88d2-5e18371cb8a7"
   },
   "outputs": [],
   "source": [
    "evaluation_report(set(range(3)), set(range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kqRroCUY2BR"
   },
   "source": [
    "This should give you a precision of 60%, a recall of 100%, and an F1-value of 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJqFla2QY2BR"
   },
   "source": [
    "## Problem 2: Span recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbFaHTyLY2BR"
   },
   "source": [
    "One of the first tasks that an information extraction system has to solve is to locate and classify (mentions of) named entities, such as persons and organizations. Here we will tackle the simpler task of recognizing **spans** of tokens that contain an entity mention, without the actual entity label.\n",
    "\n",
    "The English language model in spaCy features a full-fledged [named entity recognizer](https://spacy.io/usage/linguistic-features#named-entities) that identifies a variety of entities, and can be updated with new entity types by the user. Your task in this problem is to evaluate the performance of this component when predicting entity spans in the development data.\n",
    "\n",
    "Start by implementing a generator function that yields the gold-standard spans in a given data frame.\n",
    "\n",
    "**Hint:** The Pandas method [`itertuples()`](https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.itertuples.html) is useful when iterating over the rows in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cbGCY5CY2BR"
   },
   "outputs": [],
   "source": [
    "def gold_spans(df):\n",
    "    \"\"\"Yield the gold-standard mention spans in a data frame.\n",
    "\n",
    "    Args:\n",
    "        df: A data frame.\n",
    "\n",
    "    Yields:\n",
    "        The gold-standard mention spans in the specified data frame as\n",
    "        triples consisting of the sentence id, start position, and end\n",
    "        position of each span.\n",
    "    \"\"\"\n",
    "    # TODO: Replace the next line with your own code\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        yield (row[1],row[3],row[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXjx22FIY2BS"
   },
   "source": [
    "To test your code, you can count the spans yielded by your function. When called on the development data, you should get a total of 5,917 unique triples. The first triple and the last triple should be\n",
    "\n",
    "    ('0946-000', 2, 3)\n",
    "    ('1161-010', 1, 3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZf1d8DNY2BS",
    "outputId": "32f98c53-c863-4260-96f7-542fba9f59f7"
   },
   "outputs": [],
   "source": [
    "spans_dev_gold = set(gold_spans(df_dev))\n",
    "spans_dev_gold_l = list(gold_spans(df_dev))\n",
    "\n",
    "print(len(spans_dev_gold))\n",
    "print(spans_dev_gold_l[0])\n",
    "print(spans_dev_gold_l[5916])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9F-4u6XY2BS"
   },
   "source": [
    "Your next task is to write code that calls spaCy to predict the named entities in the development data, and to evaluate the accuracy of these predictions in terms of precision, recall, and F1. Print these scores using the function that you wrote for Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVQM__OcY2BS"
   },
   "outputs": [],
   "source": [
    "# TODO: Write code here to run and evaluate the spaCy NER on the development data\n",
    "def predict(df):\n",
    "    for row in df.itertuples():\n",
    "        sentence = nlp(row[2])\n",
    "        for ent in sentence.ents:\n",
    "            start = sentence.text.split(' ').index(ent.text.split(' ')[0])\n",
    "            yield (row[1], start, start+len(ent.text.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKmUfufRY2BT",
    "outputId": "5f204a0f-6057-46ec-c472-54a3727bee21"
   },
   "outputs": [],
   "source": [
    "preds_dev_gold = set(predict(df_dev)) #predictions of dev data\n",
    "\n",
    "evaluation_report(spans_dev_gold, preds_dev_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hzG4NeCY2BT"
   },
   "source": [
    "## Problem 3: Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9rAfDVEY2BT"
   },
   "source": [
    "As you were able to see in Problem&nbsp;2, the span accuracy of the named entity recognizer is far from perfect. In particular, only slightly more than half of the predicted spans are correct according to the gold standard. Your next task is to analyse this result in more detail.\n",
    "\n",
    "Here is a function that prints the false positives as well as the false negatives spans for a data frame, given a reference set of gold-standard spans and a candidate set of predicted spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gWQYU-oY2BT"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def error_report(df, spans_gold, spans_pred):\n",
    "    false_pos = defaultdict(list)\n",
    "    for s, b, e in spans_pred - spans_gold:\n",
    "        false_pos[s].append((b, e))\n",
    "    false_neg = defaultdict(list)\n",
    "    for s, b, e in spans_gold - spans_pred:\n",
    "        false_neg[s].append((b, e))\n",
    "    for row in df.drop_duplicates('sentence_id').itertuples():\n",
    "        if row.sentence_id in false_pos or row.sentence_id in false_neg:\n",
    "            print('Sentence:', row.sentence)\n",
    "            for b, e in false_pos[row.sentence_id]:\n",
    "                print('  FP:', ' '.join(row.sentence.split()[b:e]))\n",
    "            for b, e in false_neg[row.sentence_id]:\n",
    "                print('  FN:', ' '.join(row.sentence.split()[b:e]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjz54qwMY2BT"
   },
   "source": [
    "Use this function to inspect and analyse the errors that the automated prediction makes. Can you see any patterns? Base your analysis on the first 500 rows of the training data. Summarize your observations in a short text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ser87s8NY2BT"
   },
   "outputs": [],
   "source": [
    "# TODO: Write code here to do your analysis\n",
    "df_base = df_train.head(500)\n",
    "spans_gold = set(gold_spans(df_base))\n",
    "spans_pred = set(predict(df_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKpYHCkmY2BU",
    "outputId": "663e8f57-7fe5-4bab-f5dc-f91f2471d85f"
   },
   "outputs": [],
   "source": [
    "error_report(df_base, spans_gold, spans_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhSUIl6iY2BV"
   },
   "source": [
    "*TODO: Write a short text that summarises the errors that you observed*\n",
    "\n",
    "**Answer:**\n",
    "* Predicted 'The European Comission' instead of 'European Comission'. Some predictions contain less words than the gold-label, however it is difficult to descifer which is the logic behind the prediction. \n",
    "* Predicted dates. The gold-label set does not contain dates, therefore they will be removed from the prediction. \n",
    "* Predicted numeric values. The gold-label set does not contain numeric values, they will also be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1cuurC8Y2BV"
   },
   "source": [
    "Now, use the insights from your error analysis to improve the automated prediction that you implemented in Problem&nbsp;2. While the best way to do this would be to [update spaCy&rsquo;s NER model](https://spacy.io/usage/linguistic-features#updating) using domain-specific training data, for this lab it suffices to write code to post-process the output produced by spaCy. You should be able to improve the F1 score from Problem&nbsp;2 by at last 15 percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD1UdZywY2BV"
   },
   "outputs": [],
   "source": [
    "# TODO: Write code here to improve the span prediction from Problem 2\n",
    "def predict_improved(df):\n",
    "    wrong_label = ['DATE', 'CARDINAL', 'QUANTITY', 'PERCENT', 'MONEY', 'TIME', 'NAME', 'ORDINAL', 'PRODUCT']\n",
    "    for row in df.itertuples():\n",
    "        sentence = nlp(row[2])\n",
    "        for ent in sentence.ents:\n",
    "            if ent.label_ not in wrong_label:\n",
    "                start = sentence.text.split(' ').index(ent.text.split(' ')[0])\n",
    "                yield (row[1], start, start+len(ent.text.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6T6K4isY2BV",
    "outputId": "221ea857-47b8-46ac-fb5b-917b26f5b9eb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_dev_gold = set(predict_improved(df_dev)) #predictions of dev data\n",
    "\n",
    "evaluation_report(spans_dev_gold, preds_dev_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "hk_jGIUAY2BW",
    "outputId": "a3bbf2d9-2a42-4dc6-fba2-473f269fa520"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1f244QshY2BX"
   },
   "source": [
    "Show that you achieve the performance goal by reporting the evaluation measures that you implemented in Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZNIrOkQY2BY"
   },
   "source": [
    "Before going on, we ask you to store the outputs of the improved named entity recognizer on the development data in a new data frame. This new frame should have the same layout as the original data frame for the development data that you loaded above, but should contain the *predicted* start and end positions for each token span, rather than the gold positions. As the `label` of each span, you can use the special value `--NME--`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "4_iLf0pvY2BY",
    "outputId": "34ed3963-ab50-48f3-d7e6-53844d54a533"
   },
   "outputs": [],
   "source": [
    "# TODO: Write code here to store the predicted spans in a new data frame\n",
    "df_pred = pd.DataFrame(preds_dev_gold)\n",
    "df_pred['label'] = '--NME--'\n",
    "df_pred = df_pred.rename(columns={0: \"sentence-id\", 1: \"beg\", 2: \"end\"})\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLqUTIXgY2BZ"
   },
   "source": [
    "## Problem 4: Entity linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F64_FZtcY2BZ"
   },
   "source": [
    "Now that we have a method for predicting mention spans, we turn to the task of **entity linking**, which amounts to predicting the knowledge base entity that is referenced by a given mention. In our case, for each span we want to predict the Wikipedia page that this mention references.\n",
    "\n",
    "Start by extending the generator function that you implemented in Problem&nbsp;2 to labelled spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ss1rPnXhY2BZ"
   },
   "outputs": [],
   "source": [
    "def gold_mentions(df):\n",
    "    \"\"\"Yield the gold-standard mentions in a data frame.\n",
    "\n",
    "    Args:\n",
    "        df: A data frame.\n",
    "\n",
    "    Yields:\n",
    "        The gold-standard mention spans in the specified data frame as\n",
    "        quadruples consisting of the sentence id, start position, end\n",
    "        position and entity label of each span.\n",
    "    \"\"\"\n",
    "    # TODO: Replace the next line with your own code\n",
    "    for row in df.itertuples():\n",
    "        yield (row[1],row[3],row[4],row[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i8A8azh50je",
    "outputId": "93315d72-95c1-48cd-df07-d83d3b6c242b"
   },
   "outputs": [],
   "source": [
    "spans_dev_gold = set(gold_mentions(df_dev))\n",
    "spans_dev_gold_l = list(gold_mentions(df_dev))\n",
    "\n",
    "print(len(spans_dev_gold))\n",
    "print(spans_dev_gold_l[0])\n",
    "print(spans_dev_gold_l[5916])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UlebAM9Y2BZ"
   },
   "source": [
    "A naive baseline for entity linking on our data set is to link each mention span to the Wikipedia page name that we get when we join the tokens in the span by underscores, as is standard in Wikipedia page names. Suppose, for example, that a span contains the two tokens\n",
    "\n",
    "    Jimi Hendrix\n",
    "\n",
    "The baseline Wikipedia page name for this span would be\n",
    "\n",
    "    Jimi_Hendrix\n",
    "\n",
    "Implement this naive baseline and evaluate its performance. Print the evaluation measures that you implemented in Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSWD0mTrY2BZ"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Here and in the remainder of this lab, you should base your entity predictions on the predicted spans that you computed in Problem&nbsp;3.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CftMr-_rY2BZ"
   },
   "outputs": [],
   "source": [
    "# TODO: Write code here to implement the baseline\n",
    "def predict_linked(df):\n",
    "    wrong_label = ['DATE', 'CARDINAL', 'QUANTITY', 'PERCENT', 'MONEY', 'TIME', 'NAME', 'ORDINAL', 'PRODUCT']\n",
    "    for row in df.itertuples():\n",
    "        sentence = nlp(row[2])\n",
    "        for ent in sentence.ents:\n",
    "            if ent.label_ not in wrong_label:\n",
    "                start = sentence.text.split(' ').index(ent.text.split(' ')[0])\n",
    "                label = '_'.join(ent.text.split(' '))\n",
    "                yield (row[1], start, start+len(ent.text.split(' ')), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHkqzLlt_lcS",
    "outputId": "54a152b6-291f-42d5-ccda-a313790a9eb7"
   },
   "outputs": [],
   "source": [
    "preds_dev_gold = set(predict_linked(df_dev)) #predictions of dev data\n",
    "\n",
    "evaluation_report(spans_dev_gold, preds_dev_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DjC1GRQSAGC8",
    "outputId": "2aeff911-dae7-400c-dcd3-c97dfd53bb9b"
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(preds_dev_gold)\n",
    "df_pred = df_pred.rename(columns={0: \"sentence-id\", 1: \"beg\", 2: \"end\", 3:'label'})\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhHLNOJyY2BZ"
   },
   "source": [
    "## Problem 5: Extending the training data using the knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivGeqTnzY2Ba"
   },
   "source": [
    "State-of-the-art approaches to entity linking exploit information in knowledge bases. In our case, where Wikipedia is the knowledge base, one particularly useful type of information are links to other Wikipedia pages. In particular, we can interpret the anchor texts (the highlighted texts that you click on) as mentions of the entities (pages) that they link to. This allows us to harvest long lists of mention–entity pairings.\n",
    "\n",
    "The following cell loads a data frame summarizing anchor texts and page references harvested from the first paragraphs of the English Wikipedia. The data frame also contains all entity mentions in the training data (but not the development or the test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KODaBYC8Y2Ba"
   },
   "outputs": [],
   "source": [
    "with bz2.open('kb.tsv.bz2', 'rt') as source:\n",
    "    df_kb = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlZ6OrUSY2Ba"
   },
   "source": [
    "To understand what information is available in this data, the following cell shows the entry for the anchor text `Sweden`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "jkclNFZCY2Ba",
    "outputId": "9695d336-4e9a-446b-feb3-3b36a6e6acca"
   },
   "outputs": [],
   "source": [
    "df_kb.loc[df_kb.mention == 'Sweden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMYblsdqY2Bb"
   },
   "source": [
    "As you can see, each row of the data frame contains a pair $(m, e)$ of a mention $m$ and an entity $e$, as well as the conditional probability $P(e|m)$ for mention $m$ referring to entity $e$. These probabilities were estimated based on the frequencies of mention–entity pairs in the knowledge base. The example shows that the anchor text &lsquo;Sweden&rsquo; is most often used to refer to the entity [Sweden](http://en.wikipedia.org/wiki/Sweden), but in a few cases also to refer to Sweden&rsquo;s national football and ice hockey teams. Note that references are sorted in decreasing order of probability, so that the most probable pairing come first.\n",
    "\n",
    "Implement an entity linking method that resolves each mention to the most probable entity in the data frame. If the mention is not included in the data frame, you can predict the generic label `--NME--`. Print the precision, recall, and F1 of your method using the function that you implemented for Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXF7YP6gY2Bb"
   },
   "outputs": [],
   "source": [
    "# TODO: Write code here to implement the \"most probable entity\" method.\n",
    "\n",
    "def el_method(df):    \n",
    "    wrong_label = ['DATE', 'CARDINAL', 'QUANTITY', 'PERCENT', 'MONEY', 'TIME', 'NAME', 'ORDINAL', 'PRODUCT']\n",
    "    for row in df.itertuples():\n",
    "      sentence = nlp(row[2])\n",
    "      for ent in sentence.ents:\n",
    "        if ent.label_ not in wrong_label:\n",
    "          start = sentence.text.split(' ').index(ent.text.split(' ')[0])\n",
    "          df_ent = df_kb.entity[df_kb.mention == ent.text]\n",
    "          mention = '--NME--'\n",
    "          if df_ent.shape[0] > 0:\n",
    "            mention = df_ent.iloc[0]\n",
    "          yield (row[1], start, start+len(ent.text.split(' ')), mention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GgE6jKryY2Bb",
    "outputId": "8b0b4643-54fa-4d21-df02-d2e90908f827"
   },
   "outputs": [],
   "source": [
    "el_pred = set(el_method(df_dev))\n",
    "evaluation_report(spans_dev_gold, el_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Oqdjv62jtBTE",
    "outputId": "4e1940a2-a934-4811-ee60-3bcbb42d8ced"
   },
   "outputs": [],
   "source": [
    "df_pred_el = pd.DataFrame(el_pred)\n",
    "df_pred_el = df_pred_el.rename(columns={0: \"sentence-id\", 1: \"beg\", 2: \"end\", 3:'label'})\n",
    "df_pred_el.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEZE6nlbY2Bb"
   },
   "source": [
    "## Problem 6: Context-sensitive disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0ASr7x7Y2Bc"
   },
   "source": [
    "Consider the entity mention &lsquo;Lincoln&rsquo;. The most probable entity for this mention turns out to be [Lincoln, Nebraska](http://en.wikipedia.org/Lincoln,_Nebraska); but in pages about American history, we would be better off to predict [Abraham Lincoln](http://en.wikipedia.org/Abraham_Lincoln). This suggests that we should try to disambiguate between different entity references based on the textual context on the page from which the mention was taken. Your task in this last problem is to implement this idea.\n",
    "\n",
    "Set up a dictionary that contains, for each mention $m$ that can refer to more than one entity $e$, a separate Naive Bayes classifier that is trained to predict the correct entity $e$, given the textual context of the mention. As the prior probabilities of the classifier, choose the probabilities $P(e|m)$ that you used in Problem&nbsp;5. To let you estimate the context-specific probabilities, we have compiled a data set with mention contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaZDtBODY2Bc"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "with bz2.open('contexts.tsv.bz2') as source:\n",
    "    df_contexts = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vlRUubkY2Bc"
   },
   "source": [
    "This data frame contains, for each ambiguous mention $m$ and each knowledge base entity $e$ to which this mention can refer, up to 100 randomly selected contexts in which $m$ is used to refer to $e$. For this data, a **context** is defined as the 5 tokens to the left and the 5 tokens to the right of the mention. Here are a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "2C6SkpOQY2Bc",
    "outputId": "31c4b007-02d6-4e8e-a5d3-1f14ab07b56b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>entity</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>UEFA_Champions_League</td>\n",
       "      <td>Cup twice the first in @ and the second in 1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>FIFA_World_Cup</td>\n",
       "      <td>America 1975 and during the @ and 1978 World C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990 World Cup</td>\n",
       "      <td>1990_FIFA_World_Cup</td>\n",
       "      <td>Manolo represented Spain at the @</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990 World Cup</td>\n",
       "      <td>1990_FIFA_World_Cup</td>\n",
       "      <td>Hašek represented Czechoslovakia at the @ and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990 World Cup</td>\n",
       "      <td>1990_FIFA_World_Cup</td>\n",
       "      <td>renovations in 1989 for the @ The present capa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mention  ...                                            context\n",
       "0            1970  ...    Cup twice the first in @ and the second in 1983\n",
       "1            1970  ...  America 1975 and during the @ and 1978 World C...\n",
       "2  1990 World Cup  ...                 Manolo represented Spain at the @ \n",
       "3  1990 World Cup  ...  Hašek represented Czechoslovakia at the @ and ...\n",
       "4  1990 World Cup  ...  renovations in 1989 for the @ The present capa...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1vKyyRkY2Bd"
   },
   "source": [
    "Note that, in each context, the position of the mention is indicated by the `@` symbol.\n",
    "\n",
    "From this data frame, it is easy to select the data that you need to train the classifiers – the contexts and corresponding entities for all mentions. To illustrate this, the following cell shows how to select all contexts that belong to the mention &lsquo;Lincoln&rsquo;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flLVnwSQY2Bd",
    "outputId": "8dd5e8da-6954-4695-b26a-66b779bc5ebe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41465    Nebraska Concealed Handgun Permit In @ municip...\n",
       "41466    Lazlo restaurants are located in @ and Omaha C...\n",
       "41467    California Washington Overland Park Kansas @ N...\n",
       "41468    City Missouri Omaha Nebraska and @ Nebraska It...\n",
       "41469    by Sandhills Publishing Company in @ Nebraska USA\n",
       "                               ...                        \n",
       "41609                                      @ Leyton Orient\n",
       "41610                    English division three Swansea @ \n",
       "41611    league membership narrowly edging out @ on goa...\n",
       "41612                                          @ Cambridge\n",
       "41613                                                   @ \n",
       "Name: context, Length: 149, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.context[df_contexts.mention == 'Lincoln']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "XObK-_j0aXhq",
    "outputId": "398a1389-cffe-4da4-b7f9-7eaf63391223"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>entity</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17436</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>0.985768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden_national_football_team</td>\n",
       "      <td>0.014173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17438</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden_men's_national_ice_hockey_team</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mention                                 entity      prob\n",
       "17436  Sweden                                 Sweden  0.985768\n",
       "17437  Sweden          Sweden_national_football_team  0.014173\n",
       "17438  Sweden  Sweden_men's_national_ice_hockey_team  0.000059"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kb.loc[df_kb.mention == 'Sweden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-ryht0XaYLR",
    "outputId": "9c44eb40-0c24-4922-a4d9-9a6bd4589f5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sweden', 'Sweden_national_football_team',\n",
       "       \"Sweden_men's_national_ice_hockey_team\"], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.entity[df_contexts.mention == 'Sweden'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I_UoaYrY2Bd"
   },
   "source": [
    "Implement the context-sensitive disambiguation method and evaluate its performance. Here are some more hints that may help you along the way:\n",
    "\n",
    "**Hint 1:** The prior probabilities for a Naive Bayes classifier can be specified using the `class_prior` option. You will have to provide the probabilities in the same order as the alphabetically sorted class (entity) names.\n",
    "\n",
    "**Hint 2:** Not all mentions in the knowledge base are ambiguous, and therefore not all mentions have context data. If a mention has only one possible entity, pick that one. If a mention has no entity at all, predict the `--NME--` label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "5dKW7l1JCG21",
    "outputId": "375a5764-3d38-46b4-a70a-149c911cfd33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0947-002</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1139-003</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Wang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0960-007</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>3-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0966-050</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Isaac Viciosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0972-025</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>R. Kaluwitharana b S. Waugh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id  beg  end                        label\n",
       "0    0947-002    7    8                      English\n",
       "1    1139-003    2    3                         Wang\n",
       "2    0960-007   17   18                          3-6\n",
       "3    0966-050    1    3                Isaac Viciosa\n",
       "4    0972-025    0    5  R. Kaluwitharana b S. Waugh"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_ent(df):\n",
    "  wrong_label = ['DATE', 'CARDINAL', 'QUANTITY', 'PERCENT', 'MONEY', 'TIME', 'NAME', 'ORDINAL', 'PRODUCT']\n",
    "  for row in df.itertuples():\n",
    "    sentence = nlp(row[2])\n",
    "    for ent in sentence.ents:\n",
    "      if ent.label_ not in wrong_label:\n",
    "        start = sentence.text.split(' ').index(ent.text.split(' ')[0])\n",
    "        entity = ent.text\n",
    "        yield (row[1], start, start+len(ent.text.split(' ')), entity)\n",
    "\n",
    "df_pred_ent = pd.DataFrame(set(predict_ent(df_dev)))\n",
    "df_pred_ent = df_pred_ent.rename(columns={0: \"sentence_id\", 1: \"beg\", 2: \"end\", 3:'label'})\n",
    "df_pred_ent.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "Lk5RSU_mx95z",
    "outputId": "7ad3fc5e-f0fd-4538-9d69-e1d500c541c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1045-002</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>Middle East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1045-002</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Palestinian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>1045-002</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>1045-002</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Security Council</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  beg  end             label\n",
       "1726    1045-002   23   25       Middle East\n",
       "1884    1045-002   13   14       Palestinian\n",
       "1920    1045-002    8    9            Israel\n",
       "4651    1045-002    0    2  Security Council"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_ent[df_pred_ent.sentence_id == \"1045-002\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "ZuoIbvnzxJZ2",
    "outputId": "0724c28f-1b5f-4ca1-8bff-57182ad95c79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>1045-002</td>\n",
       "      <td>Security Council members expressed concern on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United_Nations_Security_Council</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>1045-002</td>\n",
       "      <td>Security Council members expressed concern on ...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>1045-002</td>\n",
       "      <td>Security Council members expressed concern on ...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>State_of_Palestine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>1045-002</td>\n",
       "      <td>Security Council members expressed concern on ...</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>Middle_East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  ...                            label\n",
       "2698    1045-002  ...  United_Nations_Security_Council\n",
       "2699    1045-002  ...                           Israel\n",
       "2700    1045-002  ...               State_of_Palestine\n",
       "2701    1045-002  ...                      Middle_East\n",
       "\n",
       "[4 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev[df_dev.sentence_id == \"1045-002\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bL1OPgfF2sw"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "NB_dict = {}\n",
    "\n",
    "for mention in df_pred_ent.label.unique():\n",
    "  #mention_id = '_'.join(mention.split(' '))\n",
    "  NB_dict[mention] = {}\n",
    "  if df_contexts.context[df_contexts.mention==mention].shape[0] == 0:\n",
    "    for s_id in df_pred_ent.sentence_id[df_pred_ent.label ==mention].iteritems():\n",
    "      NB_dict[mention][s_id[1]] = '--NME--'\n",
    "\n",
    "  if df_contexts.context[df_contexts.mention==mention].shape[0] == 1:\n",
    "    for s_id in df_pred_ent.sentence_id[df_pred_ent.label ==mention].iteritems():\n",
    "      NB_dict[mention][s_id[1]] = df_contexts.entity[df_contexts.mention==mention][0]\n",
    "  \n",
    "  if df_contexts.context[df_contexts.mention==mention].shape[0] > 1:\n",
    "    X = df_contexts.context[df_contexts.mention == mention]\n",
    "    y = df_contexts.entity[df_contexts.mention == mention]\n",
    "    #class_prior=df_kb.loc[df_kb.mention == mention].sort_values('entity').prob\n",
    "    pipe = Pipeline(steps=[('preprocessor', CountVectorizer()), ('model', MultinomialNB())])\n",
    "    pipe.fit(X,y)\n",
    "\n",
    "    for row in df_pred_ent.loc[df_pred_ent.label==mention].itertuples():\n",
    "      NB_dict[mention][row[1]] = pipe.predict(df_dev.sentence[df_dev.sentence_id == row[1]])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "tzkqW0zRGW1Q",
    "outputId": "aff28606-8e73-41d8-8ec1-89c9114508b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1016-012</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Israeli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>1016-012</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Netanyahu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>1016-012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Levy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  beg  end      label\n",
       "1073    1016-012    9   10    Israeli\n",
       "2288    1016-012   13   14  Netanyahu\n",
       "3871    1016-012    0    1       Levy"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_ent.loc[df_pred_ent.sentence_id==\"1016-012\"]\n",
    "#df_pred_ent.itertuples()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "4lqs0Vr_JkCT",
    "outputId": "7436f1c1-a796-404c-f88b-da2fe0414e25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1016-012</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>1016-012</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>1016-012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  beg  end    label\n",
       "1       1016-012   13   14  --NME--\n",
       "4113    1016-012    9   10   Israel\n",
       "4629    1016-012    0    1  --NME--"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_csd.loc[df_pred_csd.sentence_id==\"1016-012\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "BfMXGJ87KI_7",
    "outputId": "2fb5a6e7-0cc8-48f4-f57d-10d6c37f5dac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>entity</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mention, entity, context]\n",
       "Index: []"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.loc[df_contexts.mention == 'Levy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TWOIPRoykaq2",
    "outputId": "5a4ae2fe-ab88-4f63-8417-bdc0204102c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0966-121</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1016-012</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1034-000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Dutch_people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1017-006</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1155-013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nazi_Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0991-010</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1128-007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0984-008</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0980-003</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1089-010</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1087-004</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1030-040</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000-017</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0995-016</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1078-005</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0966-099</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1056-044</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Russia_national_football_team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1033-009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1020-002</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1144-002</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0966-016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1128-011</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1140-003</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1126-002</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1146-005</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>Baghdad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1011-007</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0963-022</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0983-005</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>English_language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1000-005</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Vienna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1096-041</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Run_(baseball)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1152-014</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>United_States_Air_Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0957-020</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1155-005</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>Tehran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1015-003</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1086-002</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1031-004</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1118-007</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0980-005</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1156-003</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0993-003</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0958-001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>New_York_City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1153-002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1056-022</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Australia_national_cricket_team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0946-006</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1004-002</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1058-008</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Indigenous_peoples_of_the_Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0990-009</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0946-004</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1054-016</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1067-002</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Scotland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  beg  end                               label\n",
       "0     0966-121    1    3                             --NME--\n",
       "1     1016-012   13   14                             --NME--\n",
       "2     1034-000    0    1                        Dutch_people\n",
       "3     1017-006    5    6                             --NME--\n",
       "4     1155-013    1    2                        Nazi_Germany\n",
       "5     0991-010    9   10                             --NME--\n",
       "6     1128-007    0    1                             --NME--\n",
       "7     0984-008   15   16                             --NME--\n",
       "8     0980-003    2    3                             Chicago\n",
       "9     1089-010   17   18                              Sweden\n",
       "10    1087-004   21   22                            Pakistan\n",
       "11    1030-040    1    2                               Tokyo\n",
       "12    1000-017    7    8                             --NME--\n",
       "13    0995-016   16   18                             --NME--\n",
       "14    1078-005    0    3                             --NME--\n",
       "15    0966-099    1    3                             --NME--\n",
       "16    1056-044    3    4       Russia_national_football_team\n",
       "17    1033-009    0    1                             --NME--\n",
       "18    1020-002   19   22                             --NME--\n",
       "19    1144-002    7    9                             --NME--\n",
       "20    0966-016    1    4                             --NME--\n",
       "21    1128-011   12   13                             --NME--\n",
       "22    1140-003   12   14                             --NME--\n",
       "23    1126-002   11   12                             --NME--\n",
       "24    1146-005   23   24                             Baghdad\n",
       "25    1011-007    4    7                             --NME--\n",
       "26    0963-022    2    4                             --NME--\n",
       "27    0983-005    1    2                    English_language\n",
       "28    1000-005   11   12                              Vienna\n",
       "29    1096-041   11   12                      Run_(baseball)\n",
       "30    1152-014   23   25             United_States_Air_Force\n",
       "31    0957-020   26   28                             --NME--\n",
       "32    1155-005   14   15                              Tehran\n",
       "33    1015-003    5    6                             --NME--\n",
       "34    1086-002    2    4                             --NME--\n",
       "35    1031-004   39   41                             --NME--\n",
       "36    1118-007    7   10                             --NME--\n",
       "37    0980-005   21   22                             --NME--\n",
       "38    1156-003   32   33                               Italy\n",
       "39    0993-003   24   25                             --NME--\n",
       "40    0958-001    0    2                       New_York_City\n",
       "41    1153-002    1    2                             Belgium\n",
       "42    1056-022    4    5     Australia_national_cricket_team\n",
       "43    0946-006   15   17                             --NME--\n",
       "44    1004-002    4    5                             --NME--\n",
       "45    1058-008    1    2  Indigenous_peoples_of_the_Americas\n",
       "46    0990-009    6    7                             --NME--\n",
       "47    0946-004   14   15                             --NME--\n",
       "48    1054-016    4    5                             --NME--\n",
       "49    1067-002    2    3                            Scotland"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pred_csd(df):\n",
    "  for row in df.itertuples():\n",
    "    entity = NB_dict[row[4]][row[1]]\n",
    "    yield (row[1], row[2], row[3], entity)\n",
    "\n",
    "csd_pred = set(pred_csd(df_pred_ent))\n",
    "df_pred_csd = pd.DataFrame(csd_pred)\n",
    "df_pred_csd = df_pred_csd.rename(columns={0: \"sentence_id\", 1: \"beg\", 2: \"end\", 3:'label'})\n",
    "df_pred_csd.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APzPChwUpfCV",
    "outputId": "d75c326c-7194-44d2-e422-3d098dbdd062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 31%\n",
      "\n",
      "Recall: 25%\n",
      "\n",
      "F1-score: 27%\n"
     ]
    }
   ],
   "source": [
    "evaluation_report(spans_dev_gold, csd_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "az_aHaGRY2Be"
   },
   "source": [
    "You should expect to see a small (around 1&nbsp;unit) increase in both precision, recall, and F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY-kpEW4Y2Be"
   },
   "source": [
    "**This was the last lab in the Text Mining course. Congratulations!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqxkUn6UY2Be"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Please read the section ‘General information’ on the ‘Labs’ page of the course website before submitting this notebook!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Kopie von TM-L5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
